{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1edbfb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Maestria\\Semestre 3\\sign_language_detection\\.venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:05:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Maestria\\Semestre 3\\sign_language_detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Maestria\\Semestre 3\\sign_language_detection\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step\n",
      "\n",
      "=== XGBoost ===\n",
      "Accuracy: 0.9657\n",
      "F1 Macro: 0.9634\n",
      "Precision Macro: 0.9637\n",
      "Recall Macro: 0.9638\n",
      "Top-3 Accuracy: 0.9891\n",
      "Tiempo de entrenamiento: 3.34 segundos\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94        56\n",
      "           1       0.99      0.99      0.99        94\n",
      "           2       0.99      0.98      0.98        85\n",
      "           3       1.00      0.99      0.99        99\n",
      "           4       0.98      1.00      0.99        99\n",
      "           5       0.99      1.00      1.00       100\n",
      "           6       0.99      0.98      0.98        83\n",
      "           7       0.99      1.00      0.99        96\n",
      "           8       0.99      0.97      0.98        90\n",
      "           9       1.00      1.00      1.00       100\n",
      "           A       0.95      0.98      0.97        86\n",
      "           B       0.98      0.97      0.97        99\n",
      "           C       0.91      0.97      0.94        98\n",
      "           D       0.92      0.92      0.92        87\n",
      "           E       0.99      1.00      0.99        74\n",
      "           F       1.00      0.96      0.98        91\n",
      "           H       0.95      1.00      0.98        63\n",
      "           I       0.98      0.98      0.98        99\n",
      "           K       0.99      0.98      0.98        91\n",
      "           L       0.97      0.97      0.97        99\n",
      "           M       0.91      0.98      0.94        61\n",
      "           N       0.95      0.89      0.92        63\n",
      "           O       0.96      0.91      0.93        74\n",
      "           P       0.94      0.97      0.96        70\n",
      "           Q       0.93      0.93      0.93        76\n",
      "           R       0.90      0.92      0.91       102\n",
      "           T       0.94      0.97      0.95        96\n",
      "           U       1.00      0.98      0.99        97\n",
      "           V       0.94      0.93      0.93        95\n",
      "           W       0.98      0.94      0.96        93\n",
      "           X       0.98      0.96      0.97        91\n",
      "           Y       0.99      0.98      0.98        95\n",
      "       space       0.92      0.85      0.89        55\n",
      "\n",
      "    accuracy                           0.97      2857\n",
      "   macro avg       0.96      0.96      0.96      2857\n",
      "weighted avg       0.97      0.97      0.97      2857\n",
      "\n",
      "Matriz de confusión:\n",
      " [[55  0  0 ...  0  0  0]\n",
      " [ 0 93  0 ...  0  0  0]\n",
      " [ 0  0 83 ...  0  0  0]\n",
      " ...\n",
      " [ 0  1  0 ... 87  0  0]\n",
      " [ 0  0  0 ...  0 93  0]\n",
      " [ 0  0  0 ...  0  0 47]]\n",
      "\n",
      "=== LogisticRegression ===\n",
      "Accuracy: 0.8222\n",
      "F1 Macro: 0.8198\n",
      "Precision Macro: 0.8257\n",
      "Recall Macro: 0.8232\n",
      "Top-3 Accuracy: 0.9555\n",
      "Tiempo de entrenamiento: 1.82 segundos\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69        56\n",
      "           1       0.78      0.93      0.84        94\n",
      "           2       0.67      0.73      0.70        85\n",
      "           3       0.69      0.78      0.73        99\n",
      "           4       0.79      0.63      0.70        99\n",
      "           5       0.70      0.73      0.72       100\n",
      "           6       0.93      0.95      0.94        83\n",
      "           7       0.94      1.00      0.97        96\n",
      "           8       0.91      0.93      0.92        90\n",
      "           9       0.90      1.00      0.95       100\n",
      "           A       0.93      0.98      0.95        86\n",
      "           B       0.71      0.96      0.82        99\n",
      "           C       0.90      0.88      0.89        98\n",
      "           D       0.91      0.77      0.83        87\n",
      "           E       0.76      0.89      0.82        74\n",
      "           F       0.82      0.80      0.81        91\n",
      "           H       0.94      0.97      0.95        63\n",
      "           I       0.85      0.92      0.88        99\n",
      "           K       0.93      0.89      0.91        91\n",
      "           L       0.77      0.87      0.82        99\n",
      "           M       0.81      0.97      0.88        61\n",
      "           N       0.93      0.86      0.89        63\n",
      "           O       0.84      0.76      0.79        74\n",
      "           P       0.87      0.86      0.86        70\n",
      "           Q       0.75      0.83      0.79        76\n",
      "           R       0.49      0.32      0.39       102\n",
      "           T       0.90      0.54      0.68        96\n",
      "           U       0.94      0.92      0.93        97\n",
      "           V       0.65      0.74      0.69        95\n",
      "           W       0.93      0.84      0.88        93\n",
      "           X       0.83      0.80      0.82        91\n",
      "           Y       0.95      0.84      0.89        95\n",
      "       space       0.78      0.65      0.71        55\n",
      "\n",
      "    accuracy                           0.82      2857\n",
      "   macro avg       0.83      0.82      0.82      2857\n",
      "weighted avg       0.82      0.82      0.82      2857\n",
      "\n",
      "Matriz de confusión:\n",
      " [[36  0  0 ...  0  0  0]\n",
      " [ 0 87  0 ...  0  0  0]\n",
      " [ 0  0 62 ...  0  0  0]\n",
      " ...\n",
      " [ 0  4  0 ... 73  0  0]\n",
      " [ 0  0  0 ...  0 80  0]\n",
      " [ 0  0  0 ...  0  0 36]]\n",
      "\n",
      "=== NeuralNetwork ===\n",
      "Accuracy: 0.9272\n",
      "F1 Macro: 0.9224\n",
      "Precision Macro: 0.9257\n",
      "Recall Macro: 0.9229\n",
      "Top-3 Accuracy: 0.9849\n",
      "Tiempo de entrenamiento: 7.90 segundos\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81        56\n",
      "           1       0.96      0.98      0.97        94\n",
      "           2       0.84      0.94      0.89        85\n",
      "           3       0.98      1.00      0.99        99\n",
      "           4       0.93      0.92      0.92        99\n",
      "           5       0.90      0.93      0.92       100\n",
      "           6       0.94      0.94      0.94        83\n",
      "           7       0.97      1.00      0.98        96\n",
      "           8       0.95      0.93      0.94        90\n",
      "           9       0.98      1.00      0.99       100\n",
      "           A       0.97      0.98      0.97        86\n",
      "           B       0.96      0.99      0.98        99\n",
      "           C       0.89      0.95      0.92        98\n",
      "           D       0.93      0.86      0.89        87\n",
      "           E       0.99      1.00      0.99        74\n",
      "           F       0.92      0.92      0.92        91\n",
      "           H       0.95      1.00      0.98        63\n",
      "           I       0.99      0.99      0.99        99\n",
      "           K       0.97      0.96      0.96        91\n",
      "           L       0.97      0.96      0.96        99\n",
      "           M       0.88      0.97      0.92        61\n",
      "           N       0.96      0.86      0.91        63\n",
      "           O       0.80      0.77      0.79        74\n",
      "           P       0.88      0.94      0.91        70\n",
      "           Q       0.80      0.92      0.86        76\n",
      "           R       0.90      0.84      0.87       102\n",
      "           T       0.95      0.86      0.91        96\n",
      "           U       0.98      0.93      0.95        97\n",
      "           V       0.89      0.80      0.84        95\n",
      "           W       0.94      0.85      0.89        93\n",
      "           X       0.85      0.97      0.91        91\n",
      "           Y       0.98      0.97      0.97        95\n",
      "       space       0.97      0.65      0.78        55\n",
      "\n",
      "    accuracy                           0.93      2857\n",
      "   macro avg       0.93      0.92      0.92      2857\n",
      "weighted avg       0.93      0.93      0.93      2857\n",
      "\n",
      "Matriz de confusión:\n",
      " [[49  0  0 ...  0  0  0]\n",
      " [ 0 92  0 ...  0  0  0]\n",
      " [ 0  0 80 ...  0  0  0]\n",
      " ...\n",
      " [ 0  1  0 ... 88  0  0]\n",
      " [ 0  0  0 ...  0 92  0]\n",
      " [ 0  0  0 ...  0  0 36]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report, f1_score,\n",
    "    precision_score, recall_score, top_k_accuracy_score\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Cargar datos\n",
    "data_dict = pickle.load(open('../model/data.pickle', 'rb'))\n",
    "data = np.asarray(data_dict['data'])\n",
    "labels = np.asarray(data_dict['labels'])\n",
    "\n",
    "# Codificar etiquetas\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "# Separar datos\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, labels_encoded, test_size=0.2, shuffle=True, stratify=labels_encoded\n",
    ")\n",
    "\n",
    "results = {}\n",
    "\n",
    "# 1. XGBoost\n",
    "start = time.time()\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb.fit(x_train, y_train)\n",
    "train_time = time.time() - start\n",
    "y_pred_xgb = xgb.predict(x_test)\n",
    "y_pred_proba_xgb = xgb.predict_proba(x_test)\n",
    "results['XGBoost'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_xgb),\n",
    "    'f1_macro': f1_score(y_test, y_pred_xgb, average='macro'),\n",
    "    'precision_macro': precision_score(y_test, y_pred_xgb, average='macro'),\n",
    "    'recall_macro': recall_score(y_test, y_pred_xgb, average='macro'),\n",
    "    'confusion_matrix': confusion_matrix(y_test, y_pred_xgb),\n",
    "    'classification_report': classification_report(y_test, y_pred_xgb, target_names=le.classes_),\n",
    "    'top3_accuracy': top_k_accuracy_score(y_test, y_pred_proba_xgb, k=3),\n",
    "    'train_time': train_time\n",
    "}\n",
    "\n",
    "# 2. Regresión Logística\n",
    "start = time.time()\n",
    "lr = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
    "lr.fit(x_train, y_train)\n",
    "train_time = time.time() - start\n",
    "y_pred_lr = lr.predict(x_test)\n",
    "y_pred_proba_lr = lr.predict_proba(x_test)\n",
    "results['LogisticRegression'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_lr),\n",
    "    'f1_macro': f1_score(y_test, y_pred_lr, average='macro'),\n",
    "    'precision_macro': precision_score(y_test, y_pred_lr, average='macro'),\n",
    "    'recall_macro': recall_score(y_test, y_pred_lr, average='macro'),\n",
    "    'confusion_matrix': confusion_matrix(y_test, y_pred_lr),\n",
    "    'classification_report': classification_report(y_test, y_pred_lr, target_names=le.classes_),\n",
    "    'top3_accuracy': top_k_accuracy_score(y_test, y_pred_proba_lr, k=3),\n",
    "    'train_time': train_time\n",
    "}\n",
    "\n",
    "# 3. Red Neuronal (Keras)\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "input_dim = x_train.shape[1]\n",
    "\n",
    "model_nn = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model_nn.fit(x_train, y_train_cat, epochs=20, batch_size=32, verbose=0)\n",
    "train_time = time.time() - start\n",
    "\n",
    "y_pred_nn = np.argmax(model_nn.predict(x_test), axis=1)\n",
    "y_pred_proba_nn = model_nn.predict(x_test)\n",
    "\n",
    "results['NeuralNetwork'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_nn),\n",
    "    'f1_macro': f1_score(y_test, y_pred_nn, average='macro'),\n",
    "    'precision_macro': precision_score(y_test, y_pred_nn, average='macro'),\n",
    "    'recall_macro': recall_score(y_test, y_pred_nn, average='macro'),\n",
    "    'confusion_matrix': confusion_matrix(y_test, y_pred_nn),\n",
    "    'classification_report': classification_report(y_test, y_pred_nn, target_names=le.classes_),\n",
    "    'top3_accuracy': top_k_accuracy_score(y_test, y_pred_proba_nn, k=3),\n",
    "    'train_time': train_time\n",
    "}\n",
    "\n",
    "# Mostrar resultados\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"F1 Macro: {metrics['f1_macro']:.4f}\")\n",
    "    print(f\"Precision Macro: {metrics['precision_macro']:.4f}\")\n",
    "    print(f\"Recall Macro: {metrics['recall_macro']:.4f}\")\n",
    "    print(f\"Top-3 Accuracy: {metrics['top3_accuracy']:.4f}\")\n",
    "    print(f\"Tiempo de entrenamiento: {metrics['train_time']:.2f} segundos\")\n",
    "    print(\"Reporte de clasificación:\")\n",
    "    print(metrics['classification_report'])\n",
    "    # Si quieres ver la matriz de confusión:\n",
    "    print(\"Matriz de confusión:\\n\", metrics['confusion_matrix'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
